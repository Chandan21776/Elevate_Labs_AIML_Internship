<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Cleaning & Missing Value Handling Tutorial</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <!-- Header -->
        <header class="header">
            <h1>üìä Data Cleaning & Missing Value Handling</h1>
            <p class="subtitle">Interactive Tutorial for Data Preprocessing</p>
        </header>

        <!-- Navigation Tabs -->
        <nav class="tabs">
            <button class="tab-btn active" data-tab="overview">Overview</button>
            <button class="tab-btn" data-tab="demo">Live Demo</button>
            <button class="tab-btn" data-tab="methods">Methods</button>
            <button class="tab-btn" data-tab="interview">Interview Q&A</button>
            <button class="tab-btn" data-tab="code">Code Examples</button>
        </nav>

        <!-- Tab Contents -->
        <div class="tab-content active" id="overview">
            <section class="section">
                <h2>üéØ Learning Objectives</h2>
                <div class="objectives-grid">
                    <div class="objective-card">
                        <span class="icon">üîç</span>
                        <h3>Identify Missing Data</h3>
                        <p>Learn to detect and analyze missing values in datasets</p>
                    </div>
                    <div class="objective-card">
                        <span class="icon">üìà</span>
                        <h3>Visualize Patterns</h3>
                        <p>Create visualizations to understand missing data distribution</p>
                    </div>
                    <div class="objective-card">
                        <span class="icon">üõ†Ô∏è</span>
                        <h3>Apply Imputation</h3>
                        <p>Use appropriate techniques to handle missing values</p>
                    </div>
                    <div class="objective-card">
                        <span class="icon">‚úÖ</span>
                        <h3>Validate Results</h3>
                        <p>Ensure data quality after cleaning operations</p>
                    </div>
                </div>
            </section>

            <section class="section">
                <h2>üìã Step-by-Step Guide</h2>
                <div class="steps">
                    <div class="step">
                        <div class="step-number">1</div>
                        <div class="step-content">
                            <h3>Load Dataset & Identify Missing Values</h3>
                            <p>Use <code>.isnull().sum()</code> to count missing values per column</p>
                            <pre><code>import pandas as pd
import numpy as np

df = pd.read_csv('dataset.csv')
missing_values = df.isnull().sum()
print(missing_values)</code></pre>
                        </div>
                    </div>

                    <div class="step">
                        <div class="step-number">2</div>
                        <div class="step-content">
                            <h3>Visualize Missing Data Patterns</h3>
                            <p>Create bar charts to see distribution of missing values</p>
                            <pre><code>import matplotlib.pyplot as plt

missing_values.plot(kind='bar')
plt.title('Missing Values by Column')
plt.show()</code></pre>
                        </div>
                    </div>

                    <div class="step">
                        <div class="step-number">3</div>
                        <div class="step-content">
                            <h3>Apply Mean/Median Imputation</h3>
                            <p>Fill numerical columns with statistical measures</p>
                            <pre><code># Mean imputation
df['age'].fillna(df['age'].mean(), inplace=True)

# Median imputation (better for skewed data)
df['salary'].fillna(df['salary'].median(), inplace=True)</code></pre>
                        </div>
                    </div>

                    <div class="step">
                        <div class="step-number">4</div>
                        <div class="step-content">
                            <h3>Apply Mode Imputation</h3>
                            <p>Fill categorical columns with most frequent value</p>
                            <pre><code># Mode imputation for categorical data
df['category'].fillna(df['category'].mode()[0], inplace=True)</code></pre>
                        </div>
                    </div>

                    <div class="step">
                        <div class="step-number">5</div>
                        <div class="step-content">
                            <h3>Remove High Missing Columns</h3>
                            <p>Drop columns with >50% missing values</p>
                            <pre><code>threshold = 0.5
missing_pct = df.isnull().sum() / len(df)
cols_to_drop = missing_pct[missing_pct > threshold].index
df.drop(columns=cols_to_drop, inplace=True)</code></pre>
                        </div>
                    </div>

                    <div class="step">
                        <div class="step-number">6</div>
                        <div class="step-content">
                            <h3>Validate Dataset</h3>
                            <p>Check data quality after cleaning</p>
                            <pre><code># Check remaining missing values
print(df.isnull().sum())

# Verify data types
print(df.dtypes)

# Check for duplicates
print(f"Duplicates: {df.duplicated().sum()}")</code></pre>
                        </div>
                    </div>

                    <div class="step">
                        <div class="step-number">7</div>
                        <div class="step-content">
                            <h3>Compare Before vs After</h3>
                            <p>Document improvements in data quality</p>
                            <pre><code>print(f"Original shape: {original_shape}")
print(f"Cleaned shape: {df.shape}")
print(f"Rows removed: {original_shape[0] - df.shape[0]}")
print(f"Columns removed: {original_shape[1] - df.shape[1]}")</code></pre>
                        </div>
                    </div>
                </div>
            </section>
        </div>

        <!-- Live Demo Tab -->
        <div class="tab-content" id="demo">
            <section class="section">
                <h2>üöÄ Interactive Data Cleaning Demo</h2>
                
                <div class="demo-controls">
                    <button id="generateData" class="btn btn-primary">Generate Sample Dataset</button>
                    <button id="analyzeData" class="btn btn-secondary" disabled>Analyze Missing Values</button>
                    <button id="cleanData" class="btn btn-success" disabled>Clean Dataset</button>
                    <button id="resetDemo" class="btn btn-warning">Reset</button>
                </div>

                <div class="demo-grid">
                    <div class="demo-section">
                        <h3>üìä Original Dataset</h3>
                        <div id="originalData" class="data-table-container">
                            <p class="placeholder">Click "Generate Sample Dataset" to begin</p>
                        </div>
                    </div>

                    <div class="demo-section">
                        <h3>üîç Missing Values Analysis</h3>
                        <div id="missingAnalysis" class="analysis-container">
                            <canvas id="missingChart"></canvas>
                        </div>
                    </div>
                </div>

                <div class="demo-section full-width">
                    <h3>‚ú® Cleaned Dataset</h3>
                    <div id="cleanedData" class="data-table-container">
                        <p class="placeholder">Clean the dataset to see results</p>
                    </div>
                </div>

                <div class="comparison-section">
                    <h3>üìà Before vs After Comparison</h3>
                    <div id="comparisonStats" class="stats-grid"></div>
                </div>
            </section>
        </div>

        <!-- Methods Tab -->
        <div class="tab-content" id="methods">
            <section class="section">
                <h2>üõ†Ô∏è Missing Value Handling Methods</h2>

                <div class="method-card">
                    <h3>1. Mean Imputation</h3>
                    <div class="method-content">
                        <p><strong>When to use:</strong> Numerical data with normal distribution</p>
                        <p><strong>Pros:</strong> Simple, preserves dataset size</p>
                        <p><strong>Cons:</strong> Reduces variance, not suitable for skewed data</p>
                        <div class="code-example">
                            <code>df['column'].fillna(df['column'].mean(), inplace=True)</code>
                        </div>
                    </div>
                </div>

                <div class="method-card">
                    <h3>2. Median Imputation</h3>
                    <div class="method-content">
                        <p><strong>When to use:</strong> Numerical data with outliers or skewed distribution</p>
                        <p><strong>Pros:</strong> Robust to outliers, simple</p>
                        <p><strong>Cons:</strong> Still reduces variance</p>
                        <div class="code-example">
                            <code>df['column'].fillna(df['column'].median(), inplace=True)</code>
                        </div>
                    </div>
                </div>

                <div class="method-card">
                    <h3>3. Mode Imputation</h3>
                    <div class="method-content">
                        <p><strong>When to use:</strong> Categorical data</p>
                        <p><strong>Pros:</strong> Appropriate for categorical variables</p>
                        <p><strong>Cons:</strong> Biases towards majority class</p>
                        <div class="code-example">
                            <code>df['column'].fillna(df['column'].mode()[0], inplace=True)</code>
                        </div>
                    </div>
                </div>

                <div class="method-card">
                    <h3>4. Forward/Backward Fill</h3>
                    <div class="method-content">
                        <p><strong>When to use:</strong> Time-series data</p>
                        <p><strong>Pros:</strong> Preserves temporal patterns</p>
                        <p><strong>Cons:</strong> Can propagate errors</p>
                        <div class="code-example">
                            <code>df.fillna(method='ffill')  # Forward fill<br>df.fillna(method='bfill')  # Backward fill</code>
                        </div>
                    </div>
                </div>

                <div class="method-card">
                    <h3>5. Deletion Methods</h3>
                    <div class="method-content">
                        <p><strong>When to use:</strong> Small percentage of missing data (<5%)</p>
                        <p><strong>Pros:</strong> No imputation bias</p>
                        <p><strong>Cons:</strong> Loss of data, potential bias if not random</p>
                        <div class="code-example">
                            <code>df.dropna()  # Drop rows with any missing<br>df.dropna(thresh=n)  # Keep rows with at least n non-null values</code>
                        </div>
                    </div>
                </div>

                <div class="method-card">
                    <h3>6. Advanced Methods</h3>
                    <div class="method-content">
                        <p><strong>KNN Imputation:</strong> Uses K-nearest neighbors</p>
                        <p><strong>Multiple Imputation:</strong> Creates multiple imputed datasets</p>
                        <p><strong>Model-based:</strong> Predicts missing values using ML models</p>
                        <div class="code-example">
                            <code>from sklearn.impute import KNNImputer<br>imputer = KNNImputer(n_neighbors=5)<br>df_imputed = imputer.fit_transform(df)</code>
                        </div>
                    </div>
                </div>
            </section>
        </div>

        <!-- Interview Q&A Tab -->
        <div class="tab-content" id="interview">
            <section class="section">
                <h2>üíº Interview Questions & Answers</h2>

                <div class="qa-card">
                    <h3 class="question">Q1: Mean vs Median Imputation - When to use which?</h3>
                    <div class="answer">
                        <p><strong>Mean Imputation:</strong></p>
                        <ul>
                            <li>Use when data is <strong>normally distributed</strong></li>
                            <li>No significant outliers present</li>
                            <li>Example: Heights, test scores in a large population</li>
                        </ul>
                        <p><strong>Median Imputation:</strong></p>
                        <ul>
                            <li>Use when data is <strong>skewed</strong> or has <strong>outliers</strong></li>
                            <li>More robust to extreme values</li>
                            <li>Example: Income data, house prices, age with outliers</li>
                        </ul>
                        <p><strong>Key Difference:</strong> Mean is affected by outliers, median is not. If one value is extremely high or low, median is the safer choice.</p>
                    </div>
                </div>

                <div class="qa-card">
                    <h3 class="question">Q2: When should rows be dropped instead of imputed?</h3>
                    <div class="answer">
                        <p><strong>Drop rows when:</strong></p>
                        <ul>
                            <li><strong>Small percentage of missing data</strong> (< 5% of total rows)</li>
                            <li><strong>Missing Completely at Random (MCAR)</strong> - no pattern to missingness</li>
                            <li>Row has <strong>multiple critical features missing</strong></li>
                            <li>Dataset is <strong>large enough</strong> that losing rows won't impact analysis</li>
                            <li><strong>Target variable is missing</strong> (can't use for supervised learning)</li>
                        </ul>
                        <p><strong>Don't drop rows when:</strong></p>
                        <ul>
                            <li>High percentage of missing data (>10%)</li>
                            <li>Missing pattern is systematic (Missing Not at Random - MNAR)</li>
                            <li>Dataset is small</li>
                            <li>Missing values carry information</li>
                        </ul>
                    </div>
                </div>

                <div class="qa-card">
                    <h3 class="question">Q3: Why is missing data harmful?</h3>
                    <div class="answer">
                        <p><strong>Missing data causes several problems:</strong></p>
                        <ul>
                            <li><strong>Reduced Statistical Power:</strong> Fewer data points = less reliable results</li>
                            <li><strong>Biased Estimates:</strong> If data isn't missing randomly, results can be skewed</li>
                            <li><strong>Model Performance Issues:</strong> Many ML algorithms can't handle missing values</li>
                            <li><strong>Invalid Conclusions:</strong> Analysis on incomplete data may lead to wrong decisions</li>
                            <li><strong>Loss of Information:</strong> Each missing value is a lost opportunity to learn</li>
                        </ul>
                        <p><strong>Example:</strong> If only wealthy people respond to an income survey, analyzing that data will give a biased view of the overall population's income.</p>
                    </div>
                </div>

                <div class="qa-card">
                    <h3 class="question">Q4: What is data leakage?</h3>
                    <div class="answer">
                        <p><strong>Data leakage</strong> occurs when information from outside the training dataset is used to create the model, leading to overly optimistic performance metrics.</p>
                        
                        <p><strong>Common causes in data cleaning:</strong></p>
                        <ul>
                            <li><strong>Imputing before splitting:</strong> Using statistics from entire dataset (including test set) for imputation</li>
                            <li><strong>Target leakage:</strong> Using information derived from the target variable</li>
                            <li><strong>Temporal leakage:</strong> Using future information to predict past events</li>
                        </ul>

                        <p><strong>Correct approach:</strong></p>
                        <pre><code># WRONG - Data leakage
df['age'].fillna(df['age'].mean())  # Uses test set info
X_train, X_test = train_test_split(df)

# CORRECT - No leakage
X_train, X_test = train_test_split(df)
mean_age = X_train['age'].mean()
X_train['age'].fillna(mean_age)
X_test['age'].fillna(mean_age)  # Use training mean only</code></pre>
                    </div>
                </div>

                <div class="qa-card">
                    <h3 class="question">Q5: What is data quality and how do you measure it?</h3>
                    <div class="answer">
                        <p><strong>Data quality</strong> refers to the condition of data based on factors like accuracy, completeness, reliability, and relevance.</p>
                        
                        <p><strong>Key dimensions of data quality:</strong></p>
                        <ul>
                            <li><strong>Completeness:</strong> Are all required values present? (Missing values %)</li>
                            <li><strong>Accuracy:</strong> Is the data correct? (Validation against ground truth)</li>
                            <li><strong>Consistency:</strong> Is data uniform across sources? (Contradictions check)</li>
                            <li><strong>Validity:</strong> Does data conform to defined formats? (Data type checks)</li>
                            <li><strong>Uniqueness:</strong> Are there duplicates? (Duplicate count)</li>
                            <li><strong>Timeliness:</strong> Is data current and up-to-date?</li>
                        </ul>

                        <p><strong>How to measure:</strong></p>
                        <pre><code># Completeness
completeness = (1 - df.isnull().sum() / len(df)) * 100

# Uniqueness
uniqueness = (1 - df.duplicated().sum() / len(df)) * 100

# Validity (example: email format)
valid_emails = df['email'].str.match(r'^[\w\.-]+@[\w\.-]+\.\w+$').sum()
validity = (valid_emails / len(df)) * 100</code></pre>
                    </div>
                </div>

                <div class="qa-card">
                    <h3 class="question">Bonus Q: What are the types of missing data?</h3>
                    <div class="answer">
                        <ul>
                            <li><strong>MCAR (Missing Completely at Random):</strong> Missingness has no relationship to any data. Safe to drop rows.</li>
                            <li><strong>MAR (Missing at Random):</strong> Missingness related to observed data, not the missing value itself. Can be handled with imputation.</li>
                            <li><strong>MNAR (Missing Not at Random):</strong> Missingness related to the unobserved value itself. Most challenging, requires domain knowledge.</li>
                        </ul>
                        <p><strong>Example:</strong> Survey about income where high earners skip the question = MNAR (missing because of the value itself).</p>
                    </div>
                </div>
            </section>
        </div>

        <!-- Code Examples Tab -->
        <div class="tab-content" id="code">
            <section class="section">
                <h2>üíª Complete Python Code Examples</h2>

                <div class="code-section">
                    <h3>Full Data Cleaning Script</h3>
                    <pre><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ========== STEP 1: Load and Explore ==========
print("=" * 50)
print("STEP 1: Loading Dataset")
print("=" * 50)

df = pd.read_csv('dataset.csv')
print(f"Dataset shape: {df.shape}")
print(f"\nFirst few rows:")
print(df.head())

original_shape = df.shape

# ========== STEP 2: Identify Missing Values ==========
print("\n" + "=" * 50)
print("STEP 2: Missing Values Analysis")
print("=" * 50)

missing_values = df.isnull().sum()
missing_percentage = (df.isnull().sum() / len(df)) * 100

missing_df = pd.DataFrame({
    'Column': missing_values.index,
    'Missing_Count': missing_values.values,
    'Missing_Percentage': missing_percentage.values
})
missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)

print("\nMissing Values Summary:")
print(missing_df)

# ========== STEP 3: Visualize Missing Data ==========
print("\n" + "=" * 50)
print("STEP 3: Visualizing Missing Data")
print("=" * 50)

if len(missing_df) > 0:
    plt.figure(figsize=(10, 6))
    plt.bar(missing_df['Column'], missing_df['Missing_Percentage'])
    plt.xlabel('Columns')
    plt.ylabel('Missing Percentage (%)')
    plt.title('Missing Data by Column')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig('missing_data_visualization.png')
    print("Visualization saved as 'missing_data_visualization.png'")

# ========== STEP 4: Remove High Missing Columns ==========
print("\n" + "=" * 50)
print("STEP 4: Removing Columns with >50% Missing")
print("=" * 50)

threshold = 0.5
cols_to_drop = missing_df[missing_df['Missing_Percentage'] > threshold * 100]['Column'].tolist()

if cols_to_drop:
    print(f"Dropping columns: {cols_to_drop}")
    df.drop(columns=cols_to_drop, inplace=True)
else:
    print("No columns to drop")

# ========== STEP 5: Impute Numerical Columns ==========
print("\n" + "=" * 50)
print("STEP 5: Imputing Numerical Columns")
print("=" * 50)

numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()

for col in numerical_cols:
    if df[col].isnull().sum() > 0:
        # Check skewness to decide mean vs median
        skewness = df[col].skew()
        
        if abs(skewness) < 1:  # Roughly normal
            impute_value = df[col].mean()
            method = "mean"
        else:  # Skewed
            impute_value = df[col].median()
            method = "median"
        
        df[col].fillna(impute_value, inplace=True)
        print(f"{col}: Imputed with {method} ({impute_value:.2f})")

# ========== STEP 6: Impute Categorical Columns ==========
print("\n" + "=" * 50)
print("STEP 6: Imputing Categorical Columns")
print("=" * 50)

categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

for col in categorical_cols:
    if df[col].isnull().sum() > 0:
        mode_value = df[col].mode()[0]
        df[col].fillna(mode_value, inplace=True)
        print(f"{col}: Imputed with mode ('{mode_value}')")

# ========== STEP 7: Remove Duplicates ==========
print("\n" + "=" * 50)
print("STEP 7: Removing Duplicates")
print("=" * 50)

duplicates = df.duplicated().sum()
print(f"Duplicate rows found: {duplicates}")

if duplicates > 0:
    df.drop_duplicates(inplace=True)
    print(f"Removed {duplicates} duplicate rows")

# ========== STEP 8: Validation ==========
print("\n" + "=" * 50)
print("STEP 8: Validation")
print("=" * 50)

remaining_missing = df.isnull().sum().sum()
print(f"Remaining missing values: {remaining_missing}")
print(f"\nData types:")
print(df.dtypes)

# ========== STEP 9: Compare Before vs After ==========
print("\n" + "=" * 50)
print("STEP 9: Before vs After Comparison")
print("=" * 50)

print(f"Original shape: {original_shape}")
print(f"Cleaned shape: {df.shape}")
print(f"Rows removed: {original_shape[0] - df.shape[0]}")
print(f"Columns removed: {original_shape[1] - df.shape[1]}")
print(f"Data completeness: {((1 - remaining_missing / df.size) * 100):.2f}%")

# ========== STEP 10: Save Cleaned Dataset ==========
print("\n" + "=" * 50)
print("STEP 10: Saving Cleaned Dataset")
print("=" * 50)

df.to_csv('cleaned_dataset.csv', index=False)
print("Cleaned dataset saved as 'cleaned_dataset.csv'")

print("\n" + "=" * 50)
print("DATA CLEANING COMPLETE!")
print("=" * 50)</code></pre>
                </div>

                <div class="code-section">
                    <h3>Create Sample Dataset with Missing Values</h3>
                    <pre><code>import pandas as pd
import numpy as np

# Set random seed for reproducibility
np.random.seed(42)

# Generate sample data
n_rows = 1000

data = {
    'id': range(1, n_rows + 1),
    'age': np.random.normal(35, 10, n_rows),
    'salary': np.random.exponential(50000, n_rows),
    'experience': np.random.normal(10, 5, n_rows),
    'department': np.random.choice(['Sales', 'IT', 'HR', 'Marketing', 'Finance'], n_rows),
    'city': np.random.choice(['New York', 'London', 'Tokyo', 'Mumbai', 'Berlin'], n_rows),
    'performance_score': np.random.uniform(1, 10, n_rows),
    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_rows),
}

df = pd.DataFrame(data)

# Introduce missing values
df.loc[df.sample(frac=0.15).index, 'age'] = np.nan
df.loc[df.sample(frac=0.20).index, 'salary'] = np.nan
df.loc[df.sample(frac=0.10).index, 'experience'] = np.nan
df.loc[df.sample(frac=0.25).index, 'department'] = np.nan
df.loc[df.sample(frac=0.30).index, 'city'] = np.nan
df.loc[df.sample(frac=0.60).index, 'performance_score'] = np.nan  # High missing
df.loc[df.sample(frac=0.12).index, 'education'] = np.nan

# Save dataset
df.to_csv('dataset.csv', index=False)
print("Sample dataset created: dataset.csv")
print(f"Shape: {df.shape}")
print(f"\nMissing values:\n{df.isnull().sum()}")</code></pre>
                </div>

                <div class="code-section">
                    <h3>Advanced: Using Scikit-learn Imputers</h3>
                    <pre><code>from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np

# Load data
df = pd.read_csv('dataset.csv')

# Separate numerical and categorical
numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

# ===== Method 1: Simple Imputer =====
print("Method 1: SimpleImputer")

# Numerical - mean
num_imputer = SimpleImputer(strategy='mean')
df[numerical_cols] = num_imputer.fit_transform(df[numerical_cols])

# Categorical - most frequent
cat_imputer = SimpleImputer(strategy='most_frequent')
df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])

print("Simple imputation complete")

# ===== Method 2: KNN Imputer =====
print("\nMethod 2: KNNImputer")

# KNN works only on numerical data
# First encode categorical
df_encoded = pd.get_dummies(df, columns=categorical_cols)

# Apply KNN imputation
knn_imputer = KNNImputer(n_neighbors=5)
df_imputed = pd.DataFrame(
    knn_imputer.fit_transform(df_encoded),
    columns=df_encoded.columns
)

print("KNN imputation complete")

# ===== Method 3: Iterative Imputer (MICE) =====
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

print("\nMethod 3: IterativeImputer (MICE)")

iter_imputer = IterativeImputer(max_iter=10, random_state=42)
df_numeric = df[numerical_cols]
df_imputed = pd.DataFrame(
    iter_imputer.fit_transform(df_numeric),
    columns=numerical_cols
)

print("Iterative imputation complete")</code></pre>
                </div>
            </section>
        </div>

        <!-- Footer -->
        <footer class="footer">
            <p>üéì Data Cleaning Tutorial | Built for Internship Training</p>
            <p>Tools: HTML, CSS, JavaScript | Data Science: Python, Pandas, NumPy</p>
        </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js"></script>
    <script src="script.js"></script>
</body>
</html>